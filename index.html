<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<link rel="StyleSheet" href="style.css" type="text/css" media="all" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Deep RL for Industrial Insertion</title>
<style type="text/css">
#primarycontent h1 {
  font-variant: small-caps;
}
#primarycontent h3 {
}
#primarycontent teasertext {
  text-align: center;
}
#primarycontent p {
  text-align: center;
}
#primarycontent {
  text-align: justify;
}
#primarycontent p {
  text-align: justify;
  padding-left: 10px;
  padding-right: 10px;
}
#primarycontent p iframe {
  text-align: center;
}
.featart {
  margin:4px;
}
.hoverdiv {
  background-color:black;
  margin-top:2px;
  margin-bottom:10px;
  width:100%;
}
.hoverdiv:hover {
  background-color:white;
}
</style>

<script type="text/javascript">
  function togglevis(elid){
    el=document.getElementById(elid);
    aelid=elid+"a";
    ael=document.getElementById(aelid);
    if(el.style.display=='none'){
      el.style.display='inline-table';
      ael.innerHTML="[Hide BibTex]";
    }else{
      el.style.display='none';
      ael.innerHTML="[Show BibTex]";
    }
  }
</script>
<script type="text/javascript"
  src="http://www.maths.nottingham.ac.uk/personal/drw/LaTeXMathML.js">
</script>
<!--
<script type="text/javascript" src="http://math.etsu.edu/LaTeXMathML/LaTeXMathML.js"></script>
<link rel="stylesheet" type="text/css" href="http://math.etsu.edu/LaTeXMathML/LaTeXMathML.standardarticle.css" />
-->

<script>
   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
   (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-93210824-1', 'auto');
    ga('send', 'pageview');
</script>

</head>
<body>
<div id="primarycontent">
<h1 align="center" itemprop="name"><strong>Meta-Reinforcement Learning for <br /> Robotic Industrial Insertion Tasks</strong></h1>

<center>
<ul id="people" itemprop="accountablePerson">
  <li><h4>
        <a href="">Gerrit Schoettler</a>,
        <a href="http://ashvin.me/">Ashvin Nair</a>,
        <a href="">Juan Aparicio Ojea</a>,
        <a href="http://homes.cs.washington.edu/~svlevine/">Sergey Levine</a>,
        <a href="https://www.linkedin.com/in/eugen-solowjow-b33a1a41/">Eugen Solowjow</a></h4></li>
</ul>
</center>

<img src="fig1.png" itemprop="image" width="800" alt="teaserImage">

<h3 style="clear:both">Abstract</h3>
<p style="padding-left: 10px; padding-right: 10px;">
Robotic insertion tasks are characterized by contact and friction mechanics, making them challenging for conventional feedback control methods due to unmodeled physical effects. Reinforcement learning (RL) is a promising approach for learning control policies in such settings. However, RL can be unsafe during exploration and might require a large amount of real-world training data, which is expensive to collect. In this paper, we study how to use meta-reinforcement learning to solve the bulk of the problem in simulation by solving a family of simulated industrial insertion tasks and then adapt policies quickly in the real world.  We demonstrate our approach by training an agent to successfully perform challenging real-world insertion tasks using less than 20 trials of real-world experience.
</p>

<!--h3 style="clear:both">Preprint</h3>
<p style="padding-left: 10px; padding-right: 10px;">
  Preprint can be found <a href="https://arxiv.org/abs/1812.03201">here</a>.
</p><-->

<h3 style="clear:both">Video</h3>
<p style="padding-left: 10px; padding-right: 10px;">
  <center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/8OXqFPbpY6A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </center>
</p>

<h3 style="clear:both">Preprint</h3>
<p style="padding-left: 10px; padding-right: 10px;">
Preprint can be accessed on <a href="https://arxiv.org/abs/2004.14404">arXiv</a>.
</p>

<h3 style="clear:both">Website Template</h3>
<p style="padding-left: 10px; padding-right: 10px;">
The template for this website has been adopted from Carl Doersch.
</p>

<h3 style="clear:both">Contact</h3>
<p style="padding-left: 10px; padding-right: 10px;">
For comments/questions, contact <a href="http://ashvin.me">Ashvin Nair</a></p>
</div>

</body>
</html>
